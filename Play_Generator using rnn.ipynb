{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aDYc6SpyvgP6"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HoK86RQchY_",
        "outputId": "f74dc3b7-a979-418a-b83a-6ba90086008e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=open(path_to_file,'rb').read().decode(encoding='utf-8')\n",
        "print('Length of text:{} characters'.format(len(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zhQIaufckEV",
        "outputId": "96af5966-7cb2-46b7-b669-9f7f2f8fb298"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text:1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4dDP92ge_re",
        "outputId": "706d9f1c-00dd-4a14-b9e4-a22d440c2009"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding"
      ],
      "metadata": {
        "id": "2ThH9M-bgvhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab=sorted(set(text))\n",
        "char2idx={u:i for i,u in enumerate(vocab)}\n",
        "idx2char=np.array(vocab)\n",
        "\n",
        "def text_to_int(text):\n",
        "  return np.array([char2idx[c] for c in text])\n",
        "\n",
        "text_as_int=text_to_int(text)"
      ],
      "metadata": {
        "id": "YgNWtnRefGN8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Text:\",text[:13])\n",
        "print(\"Encoded:\",text_to_int(text[:13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVcIHcEDfa7F",
        "outputId": "4a8644d4-8a76-4432-c3d7-3f1d6583dac7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: First Citizen\n",
            "Encoded: [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def int_to_text(ints):\n",
        "  try:\n",
        "    ints=ints.numpy()\n",
        "  except:\n",
        "    pass\n",
        "  return ''.join(idx2char[ints])\n",
        "\n",
        "print(int_to_text(text_as_int[:13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLN0VRnFf4iN",
        "outputId": "10d74bd2-d0f8-4d08-b08d-9f361f8c75a9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Traning examples"
      ],
      "metadata": {
        "id": "4fiu6Ve9gxOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length=100\n",
        "examples_per_epoch=len(text)//(seq_length+1)\n",
        "char_dataset=tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "metadata": {
        "id": "AjxkolA7gWqA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences=char_dataset.batch(seq_length+1,drop_remainder=True)"
      ],
      "metadata": {
        "id": "H5f5zu5shFYn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text=chunk[:-1]\n",
        "  target_text=chunk[1:]\n",
        "  return input_text,target_text\n",
        "dataset=sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "5OTTEos-hS7y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in dataset.take(2):\n",
        "  print(\"\\n\\nEXAMPLE\\n\")\n",
        "  print(\"INPUT\")\n",
        "  print(int_to_text(x))\n",
        "  print(\"\\nOUTPUT\")\n",
        "  print(int_to_text(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxA4T4Jxi1ga",
        "outputId": "cf16a7a9-d288-4e7a-a800-3ba794029719"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "EXAMPLE\n",
            "\n",
            "INPUT\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n",
            "\n",
            "OUTPUT\n",
            "irst Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "\n",
            "\n",
            "EXAMPLE\n",
            "\n",
            "INPUT\n",
            "are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you \n",
            "\n",
            "OUTPUT\n",
            "re all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=64\n",
        "VOCAB_SIZE=len(vocab)\n",
        "EMBEDDING_DIM=256\n",
        "RNN_UNITS=1024\n",
        "BUFFER_SIZE=10000\n",
        "data=dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE,drop_remainder=True)"
      ],
      "metadata": {
        "id": "gus3k70ajJI_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the model"
      ],
      "metadata": {
        "id": "w7cLA-HTj71v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size,embedding_dim,rnn_units,batch_size):\n",
        "  model=tf.keras.Sequential([\n",
        "      tf.keras.layers.Embedding(vocab_size,embedding_dim),\n",
        "      tf.keras.layers.LSTM(rnn_units,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'),\n",
        "      tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "model=build_model(VOCAB_SIZE,EMBEDDING_DIM,RNN_UNITS,BATCH_SIZE)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "N6wFEB8CjyoA",
        "outputId": "a4a12a3e-f143-4a62-aeeb-9fd6ddfd44cf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a loss function"
      ],
      "metadata": {
        "id": "obcMyppkoseA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch,target_example_batch in data.take(1):\n",
        "  example_batch_predictions=model(input_example_batch)\n",
        "  print(example_batch_predictions.shape,\"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc3NjpToobGO",
        "outputId": "7ee569f9-570b-4e02-b58d-de808c0a474c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(example_batch_predictions))\n",
        "print(example_batch_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS4QhHzxpQSB",
        "outputId": "b9703e77-5e8e-4c35-ead2-304b5eb57129"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n",
            "tf.Tensor(\n",
            "[[[-2.55050836e-03 -2.92298105e-03  5.10155829e-03 ...  7.62772879e-06\n",
            "    4.72863391e-03  1.73572058e-04]\n",
            "  [-1.86973577e-03 -3.54210194e-03  6.36438141e-03 ... -1.27401645e-03\n",
            "   -3.56358301e-04 -4.75702807e-03]\n",
            "  [-6.94843289e-03 -1.46182114e-03  5.85578894e-03 ... -4.10201540e-03\n",
            "    1.53742172e-03  1.43814177e-04]\n",
            "  ...\n",
            "  [ 6.28186343e-03  2.70135421e-03  3.05247202e-04 ... -6.83615636e-03\n",
            "   -1.29747316e-02 -5.85907651e-03]\n",
            "  [ 8.79418291e-03  1.09492068e-03  2.30789720e-03 ... -7.92460691e-04\n",
            "   -1.32958647e-02 -4.76150727e-03]\n",
            "  [ 9.02094413e-03  5.92649973e-04  9.38136131e-04 ... -1.31660956e-03\n",
            "   -7.19960220e-03 -2.22864398e-03]]\n",
            "\n",
            " [[ 3.27006495e-03 -1.32703326e-06 -3.63947335e-03 ...  4.87749407e-04\n",
            "    4.77255788e-03  1.33166718e-03]\n",
            "  [ 6.19166438e-03  4.21301927e-03 -4.80713649e-03 ... -1.31418731e-03\n",
            "    1.55108783e-03  2.45953701e-03]\n",
            "  [ 7.60754431e-03  4.19441704e-03 -5.05373999e-03 ... -4.05292166e-03\n",
            "   -1.29109656e-03  1.26812549e-03]\n",
            "  ...\n",
            "  [-4.26776521e-03  9.71368235e-03 -3.81940138e-03 ... -3.13345972e-03\n",
            "   -1.23012718e-02  2.38508265e-03]\n",
            "  [-2.44494691e-03  9.86583065e-03 -5.01992181e-03 ... -2.52636685e-03\n",
            "   -1.25562763e-02 -5.21328591e-04]\n",
            "  [-6.25226134e-03  5.02010901e-03 -7.20356964e-03 ...  3.14715109e-03\n",
            "   -1.23448335e-02 -3.27428873e-03]]\n",
            "\n",
            " [[ 3.92410764e-03 -6.70950743e-04 -4.72466287e-04 ... -3.94358719e-03\n",
            "   -1.16715673e-03 -6.10734569e-04]\n",
            "  [ 6.57968037e-03 -1.72182452e-04 -3.62380641e-03 ... -2.15424178e-03\n",
            "    3.96763301e-03  1.26062194e-04]\n",
            "  [ 8.95676576e-03  4.25079046e-03 -4.58708266e-03 ... -3.11874179e-03\n",
            "    1.06263987e-03  1.03819312e-03]\n",
            "  ...\n",
            "  [-9.04739648e-03  5.21200709e-03 -1.32975243e-02 ... -1.82459294e-03\n",
            "   -3.02730431e-03 -1.16023524e-02]\n",
            "  [-3.38720158e-03  6.98951446e-03 -9.36833397e-03 ... -3.79829807e-03\n",
            "   -4.60816547e-03 -8.03016964e-03]\n",
            "  [-6.35476876e-03  5.05027547e-03 -1.02462545e-02 ... -4.80769016e-03\n",
            "   -8.50150175e-03 -1.25829196e-02]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-2.42772722e-03 -2.76027364e-03  4.36407095e-03 ... -2.85490369e-03\n",
            "    4.63021453e-04  5.32553648e-04]\n",
            "  [ 2.26926338e-03 -2.02522916e-03  2.46196147e-03 ... -6.19412865e-03\n",
            "   -1.05202768e-03 -1.22430691e-04]\n",
            "  [ 4.41635493e-03 -2.61852075e-03  4.21115896e-03 ... -5.03559597e-03\n",
            "    4.27439343e-03  4.04307153e-03]\n",
            "  ...\n",
            "  [-7.89853092e-03  5.08458400e-03 -9.01486538e-03 ... -3.39313573e-03\n",
            "   -1.22427382e-02 -1.11098746e-02]\n",
            "  [-1.98016712e-03  6.07271772e-03 -5.95885515e-03 ... -5.69917960e-03\n",
            "   -1.23784160e-02 -7.81938713e-03]\n",
            "  [-4.62339784e-04  7.35940319e-03 -7.62198679e-03 ... -6.01756759e-03\n",
            "   -1.29917841e-02 -1.00246621e-02]]\n",
            "\n",
            " [[-5.25063928e-03  3.72912386e-03 -3.51185619e-04 ... -1.67078368e-04\n",
            "   -4.51492466e-04  2.18745205e-03]\n",
            "  [-3.83888860e-03 -1.10310130e-03  3.31456540e-03 ...  3.30811460e-03\n",
            "    1.78470742e-03 -1.31718838e-03]\n",
            "  [ 1.52803236e-03  1.25985034e-03  2.02619215e-03 ...  1.27753033e-03\n",
            "   -6.51437324e-04 -7.07478030e-04]\n",
            "  ...\n",
            "  [ 6.48494484e-03  2.96274526e-03  4.03761957e-03 ... -3.95168208e-05\n",
            "   -4.29346139e-04 -5.52272471e-03]\n",
            "  [ 1.90393545e-03  3.58051551e-03 -1.49281882e-03 ... -7.49975722e-03\n",
            "   -1.24132214e-03 -6.10201247e-03]\n",
            "  [ 3.22563550e-03  1.76414999e-03 -5.89583814e-03 ... -1.16492789e-02\n",
            "   -2.62134033e-03 -9.65597457e-04]]\n",
            "\n",
            " [[ 5.46259759e-03  9.03839187e-04 -1.65758992e-03 ...  1.46417762e-03\n",
            "    3.19426809e-03 -3.29287117e-03]\n",
            "  [-1.09720265e-03 -2.21007993e-03 -4.88220574e-03 ...  4.41951863e-03\n",
            "    5.56481828e-04 -3.55702383e-03]\n",
            "  [-2.19377340e-03 -2.84699490e-03 -6.74661994e-03 ...  1.85824593e-03\n",
            "    1.71540817e-03 -9.13812313e-03]\n",
            "  ...\n",
            "  [-5.46684675e-03 -3.95827374e-04 -8.80699418e-03 ...  1.60103831e-02\n",
            "   -4.13775072e-03 -8.16956442e-03]\n",
            "  [-8.73574615e-03 -1.50898483e-03 -1.16652083e-02 ...  1.71550866e-02\n",
            "   -5.03036147e-03 -8.97592865e-03]\n",
            "  [-1.17121416e-03  9.89229884e-04 -3.34283151e-03 ...  1.66858956e-02\n",
            "   -7.00403051e-03 -1.04338638e-02]]], shape=(64, 100, 65), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred=example_batch_predictions[0]\n",
        "print(len(pred))\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b49u8fiEp_Vj",
        "outputId": "ba0bc190-8918-4c74-9f87-e89da2438b4a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "tf.Tensor(\n",
            "[[-2.5505084e-03 -2.9229810e-03  5.1015583e-03 ...  7.6277288e-06\n",
            "   4.7286339e-03  1.7357206e-04]\n",
            " [-1.8697358e-03 -3.5421019e-03  6.3643814e-03 ... -1.2740165e-03\n",
            "  -3.5635830e-04 -4.7570281e-03]\n",
            " [-6.9484329e-03 -1.4618211e-03  5.8557889e-03 ... -4.1020154e-03\n",
            "   1.5374217e-03  1.4381418e-04]\n",
            " ...\n",
            " [ 6.2818634e-03  2.7013542e-03  3.0524720e-04 ... -6.8361564e-03\n",
            "  -1.2974732e-02 -5.8590765e-03]\n",
            " [ 8.7941829e-03  1.0949207e-03  2.3078972e-03 ... -7.9246069e-04\n",
            "  -1.3295865e-02 -4.7615073e-03]\n",
            " [ 9.0209441e-03  5.9264997e-04  9.3813613e-04 ... -1.3166096e-03\n",
            "  -7.1996022e-03 -2.2286440e-03]], shape=(100, 65), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_pred=pred[0]\n",
        "print(len(time_pred))\n",
        "print(time_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rWs9FHZqHNl",
        "outputId": "f2c02064-fd3b-4d7d-c165-0ab06b85984d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n",
            "tf.Tensor(\n",
            "[-2.5505084e-03 -2.9229810e-03  5.1015583e-03  6.0379057e-04\n",
            " -5.5778441e-03 -1.5981396e-04  5.2391174e-03 -4.2016208e-03\n",
            "  1.5229185e-03 -1.7385582e-04 -3.2914132e-03 -3.4975815e-03\n",
            " -7.6374522e-04 -1.3757800e-03 -3.1396316e-03 -8.8775071e-04\n",
            " -2.8316991e-03  2.4238245e-03 -2.5304237e-03  6.4579421e-04\n",
            " -2.5106415e-03  1.5388591e-03 -2.6674406e-03 -3.1622751e-03\n",
            " -5.8328882e-03  3.0453980e-03 -2.1885943e-03  7.1575510e-04\n",
            "  4.0323823e-03 -2.8721364e-03 -2.6681863e-03 -1.3003191e-03\n",
            " -2.3369649e-03 -1.3544958e-03 -1.1968422e-03 -1.2893073e-03\n",
            " -2.2598656e-03  1.4446418e-03  4.0781945e-03 -6.0613290e-03\n",
            "  3.2758941e-03  2.2682797e-03  2.6792882e-03 -1.4446389e-03\n",
            "  2.1445493e-03  9.0457303e-03 -5.1061017e-03  3.8520936e-03\n",
            "  1.5346400e-04  4.4075018e-03  3.5741981e-03 -4.7946861e-03\n",
            " -1.1232633e-04 -8.2447585e-03  3.0303027e-03  2.7955559e-03\n",
            "  5.6577835e-04 -2.7419964e-03  4.3748929e-03 -5.1823352e-03\n",
            "  4.1360655e-03  1.7851322e-03  7.6277288e-06  4.7286339e-03\n",
            "  1.7357206e-04], shape=(65,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If we want to determine the predicted character we need to sample the output distribution (pick a value based on probabillity)\n",
        "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
        "\n",
        "# now we can reshape that array and convert all the integers to numbers to see the actual characters\n",
        "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
        "predicted_chars = int_to_text(sampled_indices)\n",
        "\n",
        "predicted_chars  # and this is what the model predicted for training sequence 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Sli9FrvlqPAk",
        "outputId": "20406ef2-1876-419a-f5d0-13376c672cc0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'olLT!ODNK3WYjLi,fvnWZm:k.atUOipkmqDlGDXGpzUHKc-w;MMiWH-.NIMBepHzib?xO!..iSsyejXWgPNEHlUuFgN to \\nV\\n-j'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the model"
      ],
      "metadata": {
        "id": "yDVhCfT4rirw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(labels,logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels,logits,from_logits=True)"
      ],
      "metadata": {
        "id": "zQuUfSR8qo7x"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss=loss)"
      ],
      "metadata": {
        "id": "88wPxdHMqpYL"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating checkpoints"
      ],
      "metadata": {
        "id": "s_S965sprgK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "GAjpsPAUrAi-"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traning"
      ],
      "metadata": {
        "id": "ppl4hbDyrZ3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(data,epochs=63,callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY8ytDm2rLUT",
        "outputId": "3f090fe8-289f-4b2b-ea15-dc68d837ba58"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 73ms/step - loss: 2.8576\n",
            "Epoch 2/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 73ms/step - loss: 1.8474\n",
            "Epoch 3/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 75ms/step - loss: 1.5963\n",
            "Epoch 4/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 76ms/step - loss: 1.4704\n",
            "Epoch 5/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 77ms/step - loss: 1.3973\n",
            "Epoch 6/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - loss: 1.3439\n",
            "Epoch 7/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - loss: 1.3059\n",
            "Epoch 8/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 76ms/step - loss: 1.2693\n",
            "Epoch 9/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - loss: 1.2343\n",
            "Epoch 10/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - loss: 1.2017\n",
            "Epoch 11/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - loss: 1.1695\n",
            "Epoch 12/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - loss: 1.1350\n",
            "Epoch 13/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 76ms/step - loss: 1.1069\n",
            "Epoch 14/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 75ms/step - loss: 1.0671\n",
            "Epoch 15/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 75ms/step - loss: 1.0345\n",
            "Epoch 16/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - loss: 0.9996\n",
            "Epoch 17/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - loss: 0.9634\n",
            "Epoch 18/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 75ms/step - loss: 0.9275\n",
            "Epoch 19/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 76ms/step - loss: 0.8913\n",
            "Epoch 20/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 75ms/step - loss: 0.8543\n",
            "Epoch 21/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 75ms/step - loss: 0.8192\n",
            "Epoch 22/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - loss: 0.7899\n",
            "Epoch 23/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 75ms/step - loss: 0.7545\n",
            "Epoch 24/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - loss: 0.7261\n",
            "Epoch 25/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 76ms/step - loss: 0.6940\n",
            "Epoch 26/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 76ms/step - loss: 0.6715\n",
            "Epoch 27/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 76ms/step - loss: 0.6462\n",
            "Epoch 28/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 76ms/step - loss: 0.6237\n",
            "Epoch 29/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - loss: 0.6036\n",
            "Epoch 30/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 76ms/step - loss: 0.5849\n",
            "Epoch 31/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 75ms/step - loss: 0.5679\n",
            "Epoch 32/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - loss: 0.5509\n",
            "Epoch 33/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - loss: 0.5343\n",
            "Epoch 34/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 73ms/step - loss: 0.5216\n",
            "Epoch 35/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - loss: 0.5096\n",
            "Epoch 36/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 76ms/step - loss: 0.4984\n",
            "Epoch 37/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - loss: 0.4897\n",
            "Epoch 38/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 73ms/step - loss: 0.4826\n",
            "Epoch 39/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - loss: 0.4721\n",
            "Epoch 40/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 76ms/step - loss: 0.4662\n",
            "Epoch 41/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 74ms/step - loss: 0.4582\n",
            "Epoch 42/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 74ms/step - loss: 0.4541\n",
            "Epoch 43/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 77ms/step - loss: 0.4468\n",
            "Epoch 44/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 74ms/step - loss: 0.4394\n",
            "Epoch 45/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - loss: 0.4364\n",
            "Epoch 46/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - loss: 0.4310\n",
            "Epoch 47/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - loss: 0.4287\n",
            "Epoch 48/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - loss: 0.4218\n",
            "Epoch 49/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - loss: 0.4194\n",
            "Epoch 50/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - loss: 0.4165\n",
            "Epoch 51/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - loss: 0.4148\n",
            "Epoch 52/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - loss: 0.4114\n",
            "Epoch 53/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 75ms/step - loss: 0.4116\n",
            "Epoch 54/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - loss: 0.4063\n",
            "Epoch 55/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - loss: 0.4066\n",
            "Epoch 56/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - loss: 0.4019\n",
            "Epoch 57/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 73ms/step - loss: 0.3991\n",
            "Epoch 58/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - loss: 0.4019\n",
            "Epoch 59/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - loss: 0.3989\n",
            "Epoch 60/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - loss: 0.3966\n",
            "Epoch 61/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - loss: 0.3947\n",
            "Epoch 62/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - loss: 0.3930\n",
            "Epoch 63/63\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - loss: 0.3920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the model"
      ],
      "metadata": {
        "id": "P5O-lrQer5lY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)"
      ],
      "metadata": {
        "id": "ZN07NW2oru19"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf, os\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "print(\"Latest checkpoint found:\", latest_checkpoint)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkJ8D5Zfr42X",
        "outputId": "80c991ac-399f-4b71-a3bf-5044e27794cf"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latest checkpoint found: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"./training_checkpoints/ckpt_10.weights.h5\"\n",
        "print(\"Attempting to load:\", checkpoint_path)\n",
        "model.load_weights(checkpoint_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVrm-7DGsJYe",
        "outputId": "67900e11-3945-4cda-e0c0-695643eb5ab6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to load: ./training_checkpoints/ckpt_10.weights.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating text"
      ],
      "metadata": {
        "id": "FyceAxuasIbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model,start_string):\n",
        "  num_generate=800\n",
        "  input_eval=[char2idx[s] for s in start_string]\n",
        "  input_eval=tf.expand_dims(input_eval,0)\n",
        "\n",
        "  text_generated=[]\n",
        "  temperature=1.0\n",
        "\n",
        "  # Access the LSTM layer and call reset_states()\n",
        "  for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.LSTM):\n",
        "      layer.reset_states()\n",
        "      break\n",
        "\n",
        "  for i in range(num_generate):\n",
        "    predictions=model(input_eval)\n",
        "    predictions=tf.squeeze(predictions,0)\n",
        "    predictions=predictions/temperature\n",
        "    prediction_id=tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()\n",
        "    input_eval=tf.expand_dims([prediction_id],0)\n",
        "    text_generated.append(idx2char[prediction_id])\n",
        "  return(start_string+''.join(text_generated))"
      ],
      "metadata": {
        "id": "Zrba49PEsKub"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp=input(\"Type a starting string: \")\n",
        "print(generate_text(model,inp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO3n3E78uGXW",
        "outputId": "59219e54-a159-4edc-e12c-30ff87477946"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type a starting string: Romeo\n",
            "Romeong age.\n",
            "\n",
            "GLOUCESTER:\n",
            "He provided, even to many age and livit\n",
            "Lady guess me and all in like death\n",
            "Breaking the exite hath preterved perfuition;\n",
            "For being we have relet.\n",
            "\n",
            "Priviols\n",
            "Whom your son Marguates:\n",
            "Pardon wanter, rascals.\n",
            "\n",
            "GLOUCESTER:\n",
            "Soldiers art thou that be special gast, I pray thee;\n",
            "For shines it best advented by some own desperaze looks! Please you, hear't; let you move merry both become.\n",
            "\n",
            "ESCALUS:\n",
            "Do you sleep? 'tis I move yet I have effeace\n",
            "By offiering Blants and pawngry, yonder.\n",
            "\n",
            "GLOUCESTER:\n",
            "Then. Buck'dlasted him, you were comf;\n",
            "And we refuse you.\n",
            "\n",
            "First Servant:\n",
            "Fair sisternows, my lords, my lord, we parted\n",
            "That scrong'd the nose but occasion merety me.\n",
            "If he never woo'd tes malking offenders.\n",
            "\n",
            "CORIOLANUS:\n",
            "No, behought your curst: how is it aw xainted:\n",
            "We thank you with all\n"
          ]
        }
      ]
    }
  ]
}